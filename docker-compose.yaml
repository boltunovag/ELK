version: '3.7'
services:
  elasticsearch:
    image: elasticsearch:7.17.9
    container_name: elasticsearch
    environment:
      - xpack.security.enabled=false
      - discovery.type=single-node
      # Установка имени кластера (из предыдущего задания)
      - cluster.name=my-unique-cluster-name-12345
    ulimits:
      memlock:
        soft: -1
        hard: -1
      nofile:
        soft: 65536
        hard: 65536
    cap_add:
      - IPC_LOCK
    volumes:
      - elasticsearch-data:/usr/share/elasticsearch/data
      # Добавляем volume для конфигов Logstash
      - ./elasticsearch/config/elasticsearch.yml:/usr/share/elasticsearch/config/elasticsearch.yml:ro
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - elk

  kibana:
    container_name: kibana
    image: kibana:7.17.9
    environment:
      - ELASTICSEARCH_HOSTS=http://elasticsearch:9200
    ports:
      - 5601:5601
    depends_on:
      - elasticsearch
    networks:
      - elk

  nginx:
    image: nginx:latest
    container_name: nginx
    ports:
      - "8080:80" # Пробрасываем порт 8080 хоста на порт 80 контейнера
    volumes:
      # Пробрасываем стандартные логи nginx в директорию хоста
      - ./nginx/logs:/var/log/nginx
      # Можно добавить кастомный конфиг, если нужно
      # - ./nginx/conf:/etc/nginx/conf.d:ro
    networks:
      - elk
    depends_on:
      - elasticsearch # Не обязательно для nginx, но логично

  logstash:
    image: logstash:7.17.9
    container_name: logstash
    # volumes:
    #   - ./logstash/pipeline:/usr/share/logstash/pipeline:ro
    #   - ./logstash/config/logstash.yml:/usr/share/logstash/config/logstash.yml:ro
    #   - ./nginx/logs:/var/log/nginx:ro # Даем Logstash доступ к логам Nginx
    command: >
      bash -c "
        # Создаем pipeline конфигурацию на лету
        cat << 'EOF' > /usr/share/logstash/pipeline/logstash.conf
        input {
          file {
            path => "/var/log/nginx/access.log"
            start_position => "beginning"
            sincedb_path => "/dev/null" # Для тестирования, чтобы читать файл с начала каждый раз
            codec => "json"
          }
        }
        filter {
          if [message] =~ /^\{.*\}$/ { # Проверяем, является ли сообщение JSON
             json {
               source => "message"
             }
          } else {
            # Если не JSON, парсим стандартный формат лога Nginx
            grok {
              match => { "message" => "%{IPORHOST:clientip} %{USER:ident} %{USER:auth} \[%{HTTPDATE:timestamp}\] \"%{WORD:verb} %{DATA:request} HTTP/%{NUMBER:httpversion}\" %{NUMBER:response:int} (?:%{NUMBER:bytes:int}|-) (?:"(?:%{URI:referrer}|-)\" )?"%{DATA:agent}\"" }
            }
            date {
              match => [ "timestamp", "dd/MMM/yyyy:HH:mm:ss Z" ]
              target => "@timestamp"
            }
            mutate {
              remove_field => [ "timestamp" ] # Удаляем оригинальное поле timestamp
            }
          }
        }
        output {
          elasticsearch {
            hosts => ["http://elasticsearch:9200"]
            index => "nginx-logs-%{+YYYY.MM.dd}"
          }
          # stdout { codec => rubydebug } # Раскомментируйте для отладки в консоли
        }
        EOF
        # Запускаем Logstash с созданной конфигурацией
        /usr/local/bin/docker-entrypoint
      "
    volumes:
      - ./nginx/logs:/var/log/nginx:ro # Даем Logstash доступ к логам Nginx
    depends_on:
      - elasticsearch
      - nginx
    networks:
      - elk

volumes:
  elasticsearch-data:
    driver: local
  # elasticsearch-config:
  #   driver: local

networks:
  elk:
    driver: bridge
